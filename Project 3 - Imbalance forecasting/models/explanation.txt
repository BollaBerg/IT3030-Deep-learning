I haven't always selected the option with the lowest loss, but rather the one with the best plot.
This is due to things such as optimizing for outliers may lower the loss while actually making the predictions worse.

1_all_off
    - All optional features are off
    - Keep model after 19 epochs
    - Loss = 0.00043777800272229965

2_time_on
    - Representation of time of day, day of week and day of year on 
    - Keep model after 21 epochs
    - Loss = 0.00035308304715704527

3_hanging_y
    - Representation of target 24 and 48 hours ago is on
    - Keep model after 13 epochs
    - Loss = 0.0003720217605660804

4_all_on
    - All optional features are on
    - Keep model after 18 epochs
    - Loss = 0.00031870206545889565

5_day_week
    - Representation of time-of-day and day-of-week is on
    - Keep model after 10 epochs
    - Loss = 0.00048646803641057306

6_day_year_hanging
    - Representation of day-of-year, day-of-year and target 24 and 48 hours ago is on
    - Keep model after 18 epochs
    - Loss = 0.00029655893611071194

7_day_year_targets_more_memory
    - Representation like 6, but with 30-steps long inputs
    - Keep model after 19 epochs
    - Loss = 0.0003054171305916621

8_randomness_last_y
    - Added randomness to column last_y
    - Keep model after 17 epochs
    - Loss = 0.00790548203853022

9_task_2_from_6
    - Solution for task 5.2.2 (forecasting structural difference)
    - Keep model after 13 epochs
    - Loss = 0.00048563732064687816

9_task_2_from_6_epoch_21
    - Solution for task 5.2.2
    - Keep model after 21 epochs
    - Loss = 0.00033941206782641965

10_6_with_dropout
    - Same as 6, but with a Dropout layer between LSTM-cells and output layer, with p = 0.4
    - Keep model after 16 epochs
    - Loss = 0.0005845413266154334

11_6_with_smaller_depth
    - Same as 6, but with only 1 layer of LSTM-cells
    - Keep model after 18 epochs
    - Loss = 0.00030602913191776543

12_6_with_smaller_depth_with_dropout
    - Combination of 10 and 11
    - Keep model after 11 epochs
    - Loss = 0.0006421665918104739

13_task_2_all_off
    - Solution for task 5.2.2, with all optional parameters off
    - Keep model after 19 epochs
    - Loss = 0.0003458248955242506

14_task_2_from_6_with_dropout
    - Adaptation of 9, with Dropout layer (p = 0.5)
    - Keep model after 7 epochs
    - Loss = 0.001016360446260862
    - Note: This model learnt to create a line at 0, which is pretty interesting (but absolutely useless)
